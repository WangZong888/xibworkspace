server.port=8000
spring.application.name=xgh
#kafka configuration
spring.kafka.producer.bootstrap-servers=192.168.107.34:9092,192.168.107.29:9092,192.168.107.35:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#topic
kafka.app.topic.producer=xiaguohang_order_apply


#kafka configuration

#指定消息被消费之后自动提交偏移量，以便下次继续消费
spring.kafka.consumer.enable-auto-commit=true
#指定消息组
spring.kafka.consumer.group-id=xgh
#指定kafka服务器地址
spring.kafka.consumer.bootstrap-servers=192.168.107.34:9092,192.168.107.29:9092,192.168.107.35:9092
#指定从最近地方开始消费(earliest)
spring.kafka.consumer.auto-offset-reset=latest

spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#topic
kafka.app.topic.consumer=xiaguohang_order_apply

##原始数据kafka读取
#kafka.consumer.servers=192.168.107.34:9092,192.168.107.29:9092,192.168.107.35:9092
#kafka.consumer.enable.auto.commit=true
#kafka.consumer.session.timeout=20000
#kafka.consumer.auto.commit.interval=100
#kafka.consumer.auto.offset.reset=latest
#kafka.consumer.topic=xiaguohang_order_apply
#kafka.consumer.group.id=xgh
#kafka.consumer.concurrency=10
#
##协议转换后存储kafka
#kafka.producer.servers=192.168.107.34:9092,192.168.107.29:9092,192.168.107.35:9092
#kafka.producer.topic=xiaguohang_order_apply
#kafka.producer.retries=0
#kafka.producer.batch.size=4096
#kafka.producer.linger=1
#kafka.producer.buffer.memory=40960
